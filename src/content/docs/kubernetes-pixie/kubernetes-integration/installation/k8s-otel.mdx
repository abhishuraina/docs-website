---
title: 'OpenTelemetry for Kubernetes'
tags:
    - Kubernetes integration
    - OpenTelemetry
metaDescription: "Learn how to monitor your Kubernetes Cluster using OpenTelemetry"
freshnessValidatedDate: 2024-07-23
---

<Callout title="preview">
  We're still working on this feature, but we'd love for you to try it out!

  This feature is currently provided as part of a preview program pursuant to our [pre-release policies](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy).
</Callout>

OpenTelemetry observability for Kubernetes provides complete, open-source setup paired with a top-notch Kubernetes UI that is already compatible with our proprietary Kubernetes instrumentation. Our Kubernetes UIs are designed to be provider agnostic, allowing you to select either OpenTelemetry or New Relic instrumentation based on your needs.

This document outlines the process for monitoring a Kubernetes cluster using OpenTelemetry. It involves the installation of the [`nr-k8s-otel-collector`](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector) Helm chart within the cluster and the deployment of the necessary Collectors to enable first-class observability.

By integrating Kubernetes components into the OpenTelemetry Collector, we can transmit metrics, events, and logs directly to New Relic. These telemetry signals automatically enhance our out-of-the-box experiences such as the [Kubernetes Navigator](/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/#navigator-preview), [overview dashboard](/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/#cluster-overview-dashboard), [Kubernetes events](/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/#browse-your-kubernetes-events), or [Kubernetes APM summary page](/docs/apm/apm-ui-pages/monitoring/kubernetes-summary-page/).

## How it works? [#how-works]

The [`nr-k8s-otel-collector`](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector) Helm chart deploys these OpenTelemetry Collectors:

* **Deamonset Collector**: Deployed on each worker node and responsible for gathering metrics from the underlying host in the node, the `cAdvisor`, the  `Kubelet`, and collecting logs from the containers.

* **Deployment collector**: Deployed on the control plane node and responsible for gathering metrics of Kube state metrics and Kubernetes cluster events.

  <img
    title="K8s OpenTelemetry diagram"
    alt="K8s OpenTelemetry diagram"
    src="/images/infrastructure_diagram_k8s-otel-stack.webp"
  />

## Requirements [#requirements]

To send Kubernetes telemetry data to New Relic, we need an OpenTelemetry Collector. Our New Relic distribution of OpenTelemetry (NRDOT) is already set up to automatically monitor a Kubernetes cluster. It does this by deploying all the necessary components through our [`nr-k8s-otel-collector`](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector) Helm chart.

If you switch to a different OpenTelemetry Collector, make sure it has all the key components you need:

* [Attributes processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/attributesprocessor)
* [Filter processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor)
* [Filelog receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver)
* [GroupByAttrs processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/groupbyattrsprocessor)
* [Hostmetrics receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/hostmetricsreceiver)
* [K8sAttributes processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/k8sattributesprocessor)
* [K8sevents receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/k8seventsreceiver)
* [Kubelet receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kubeletstatsreceiver)
* [MetricsTransform processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor)
* [Prometheus receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver)
* [ResourceDetection processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourcedetectionprocessor)
* [Resource processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourceprocessor)
* [Transform processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor)


<Callout variant="tip">

    Interested in using our Kubernetes OpenTelemetry observability, but don't want to install our Helm chart?

    1. Make sure that your Collector includes the previously highlighted components.
    2. Follow the setup instructions provided in this [document](https://github.com/newrelic/helm-charts/blob/master/charts/nr-k8s-otel-collector/collector.md) to configure your collector appropriately.

</Callout>


## Install your Kubernetes cluster with OpenTelemetry [#install]

To get OpenTelemetry up and running in your cluster, follow these steps:

1. Download the [Helm chart values file](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector/values.yaml#L20-L24) adapt it to meet your specific requirements.

   * Cluster name and <InlinePopover type="licenseKey"/> are mandatory.

   * Check the entire list of [configuration parameters](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#values).

2. Install the [Helm chart](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector) together with the values file.

   ```shell
   helm repo add newrelic https://helm-charts.newrelic.com
   helm upgrade nr-k8s-otel-collector newrelic/nr-k8s-otel-collector -f your-custom-values.yaml -n newrelic --create-namespace --install
   ```

3. Ensure the pods have been successfully spun up.

   ```shell
       kubectl get pods -n newrelic --watch
   ```

4. Make sure New Relic is getting the data it needs, including metrics, events, and logs, by running the right queries. See [Introduction to the query builder](/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/) for more information.

   ```sql
   FROM Metric SELECT * WHERE k8s.cluster.name='<CLUSTER_NAME>'
   FROM InfrastructureEvent SELECT * WHERE k8s.cluster.name='<CLUSTER_NAME>'
   FROM Log SELECT * WHERE k8s.cluster.name='<CLUSTER_NAME>'
   ```

5. If you're using a GKE AutoPilot cluster, it's necessary to apply the following configuration in your `values.yaml` file to ensure compatibility and proper functionality of the OpenTelemetry Collectors.

   ```yaml
   privileged: false
   receivers:
       filelog:
           enabled: false
   daemonset:
       containerSecurityContext:
           privileged: false
   ```

## Uninstall your Kubernetes cluster with OpenTelemetry [#uninstall]

To stop monitoring a Kubernetes cluster with OpenTelemetry, run this command:

```shell
    helm uninstall nr-k8s-otel-collector -n newrelic
```

## Reduce data ingest [#reduce-data-ingest]

The `LowDataMode` option is enabled by default to ingest only the metrics required by our Kubernetes UIs.

If you need to cut down even more on data ingestion, increase the scrape interval in the [`nr-k8s-otel-collector` chart values](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#values) for each deployed component.

## Metrics [#metrics]

* [Metrics - Full list](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector/docs/metrics-full.md)

* [Metrics - `LowDataMode` list](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector/docs/metrics-lowDataMode.md)

## Find and use data [#find]

Check out these documents to learn more on how to find data:

* [Explore your Kubernetes cluster](/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/) to know the status of your cluster, from the control plane to nodes and pods.

* [Kubernetes APM summary page](/docs/apm/apm-ui-pages/monitoring/kubernetes-summary-page/) which offers insights into your Kubernetes integration alongside your monitored applications.


## Mapping of Kubernetes OpenTelemetry metrics to New Relic integration metrics [#mapping]

<CollapserGroup>

    <Collapser 
    id="k8s-otel-metrics" 
    title="Kubernetes OpenTelemetry metrics to New Relic integration metrics"
    >

The following table maps the Kubernetes OpenTelemetry metrics to the New Relic integration metrics:

<table>
    <thead>
        <tr>
            <th>Component</th>
            <th>Receiver</th>
            <th>Metric</th>
            <th>Attribute name</th>
            <th>New Relic Event Name</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
        <td>API Server</td>
        <td>Prometheus Receiver</td>
        <td>apiserver_storage_objects</td>
        <td>apiserverStorageObjects_resource_RESOURCE-KIND</td>
        <td>K8sApiServerSample</td>
        <td>Gauge</td>
        <td>Number of objects stored in the API server.</td>
        </tr>
        <tr>
        <td>API Server</td>
        <td>Prometheus Receiver</td>
        <td>go_goroutines</td>
        <td>goGoroutines</td>
        <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
        <td>Gauge</td>
        <td>Number of goroutines that currently exist.</td>
        </tr>
        <tr>
        <td>API Server</td>
        <td>Prometheus Receiver</td>
        <td>go_threads</td>
        <td>goThreads</td>
        <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
        <td>Gauge</td>
        <td>Number of OS threads created.</td>
        </tr>
        <tr>
        <td>API Server</td>
        <td>Prometheus Receiver</td>
        <td>process_resident_memory_bytes</td>
        <td>processResidentMemoryBytes</td>
        <td>K8sApiServerSample</td>
        <td>Gauge</td>
        <td>Resident memory size in bytes.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_cpu_cfs_periods_total</td>
        <td>containerCpuCfsPeriodsTotal</td>
        <td>K8sContainerSample</td>
        <td>Counter</td>
        <td>Total number of elapsed enforcement period intervals.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_cpu_cfs_throttled_periods_total</td>
        <td>containerCpuCfsThrottledPeriodsTotal</td>
        <td>K8sContainerSample</td>
        <td>Counter</td>
        <td>Total number of throttled period intervals.</td>
        </tr>
        <tr>
        <td></td>
        <td>Prometheus Receiver</td>
        <td>container_cpu_usage_seconds_total</td>
        <td>cpuUsedCores</td>
        <td>K8sContainerSample</td>
        <td>Counter</td>
        <td>Total CPU time consumed.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_memory_working_set_bytes</td>
        <td>memoryWorkingSetBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Working set size of memory in bytes.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_network_receive_bytes_total</td>
        <td>net.rxBytesPerSecond</td>
        <td>K8sPodSample</td>
        <td>Counter</td>
        <td>Cumulative count of bytes received.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_network_receive_errors_total</td>
        <td>net.txBytesPerSecond</td>
        <td>memoryRequestedBytes</td>
        <td>Counter</td>
        <td>Cumulative count of receive errors encountered.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_network_transmit_bytes_total</td>
            <td>net.errorsPerSecond</td>
        <td>K8sPodSample</td>
        <td>Counter</td>
        <td>Cumulative count of bytes transmitted.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_network_transmit_errors_total</td>
        <td></td>
        <td></td>
        <td>Counter</td>
        <td>Cumulative count of transmit errors encountered.</td>
        </tr>
        <tr>
        <td>cAdvisor</td>
        <td>Prometheus Receiver</td>
        <td>container_spec_memory_limit_bytes</td>
        <td>memoryLimitBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Memory limit of the container in bytes.</td>
        </tr>
        <tr>
        <td>Controller Manager</td>
        <td>Prometheus Receiver</td>
        <td>go_goroutines</td>
        <td>goGoroutines</td>
        <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
        <td>Gauge</td>
        <td>Number of goroutines that currently exist.</td>
        </tr>
        <tr>
        <td>Controller Manager</td>
        <td>Prometheus Receiver</td>
        <td>process_resident_memory_bytes</td>
        <td>processResidentMemoryBytes</td>
        <td>K8sControllerManagerSample</td>
        <td>Gauge</td>
        <td>Resident memory size in bytes.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>container.cpu.utilization</td>
        <td>cpuCoresUtilization</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>CPU utilization percentage of the container.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>container.filesystem.capacity</td>
        <td>fsCapacityBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Total filesystem capacity for the container.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>container.filesystem.usage</td>
        <td>fsUsedBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Used filesystem space for the container.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>container.memory.usage</td>
        <td>memoryUsedBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Total memory usage of the container.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>Prometheus Receiver</td>
        <td>go_goroutines</td>
        <td>goGoroutines</td>
        <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
        <td>Gauge</td>
        <td>Number of goroutines that currently exist.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>Prometheus Receiver</td>
        <td>go_threads</td>
        <td>goThreads</td>
        <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
        <td>Gauge</td>
        <td>Number of OS threads created.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.cpu.time</td>
        <td>cpuUsedCoreMilliseconds</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Total CPU time used by the node.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.cpu.utilization</td>
        <td>allocatableCpuCoresUtilization</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>CPU utilization percentage of the node.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.filesystem.capacity</td>
        <td>fsCapacityBytes</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Total filesystem capacity for the node.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.filesystem.usage</td>
        <td>fsUsedBytes</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Used filesystem space for the node.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.memory.available</td>
        <td>memoryAvailableBytes</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Available memory for the node.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.node.memory.working_set</td>
        <td>memoryWorkingSetBytes</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Working set size of the node memory.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.pod.filesystem.available</td>
        <td>fsAvailableBytes</td>
        <td>K8sVolumeSample</td>
        <td>Gauge</td>
        <td>Available filesystem space for the pod.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.pod.filesystem.capacity</td>
        <td>fsCapacityBytes</td>
        <td>K8sVolumeSample</td>
        <td>Gauge</td>
        <td>Total filesystem capacity for the pod.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.pod.filesystem.usage</td>
        <td>fsUsedBytes</td>
        <td>K8sVolumeSample</td>
        <td>Gauge</td>
        <td>Used filesystem space for the pod.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>KubeletStats Receiver</td>
        <td>k8s.pod.memory.working_set</td>
        <td>memoryWorkingSetBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Working set size of the pod memory.</td>
        </tr>
        <tr>
        <td>Kubelet</td>
        <td>Prometheus Receiver</td>
        <td>process_resident_memory_bytes</td>
        <td>processResidentMemoryBytes</td>
        <td>K8sApiServerSample</td>
        <td>Gauge</td>
        <td>Resident memory size in bytes.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_cronjob_created</td>
        <td>createdAt</td>
        <td>K8sCronjobSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the CronJob.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_cronjob_spec_suspend</td>
        <td>isSuspended</td>
        <td>K8sCronjobSample</td>
            <td>Gauge</td>
        <td>Suspend flag of the CronJob.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_cronjob_status_active</td>
        <td>isActive</td>
        <td>K8sCronjobSample</td>
        <td>Gauge</td>
        <td>Number of active CronJob instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_cronjob_status_last_schedule_time</td>
        <td>lastScheduledTime</td>
        <td>K8sCronjobSample</td>
        <td>Gauge</td>
        <td>Last schedule time of the CronJob.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_created</td>
        <td>createdAt</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the DaemonSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_status_desired_number_scheduled</td>
        <td>podsScheduled</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Desired number of scheduled DaemonSet instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_status_number_misscheduled</td>
        <td>podsMisscheduled</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Number of misscheduled DaemonSet instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_status_number_ready</td>
        <td>podsReady</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Number of ready DaemonSet instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_status_number_unavailable</td>
        <td>podsUnavailable</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Number of unavailable DaemonSet instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_daemonset_status_updated_number_scheduled</td>
        <td>podsUpdatedScheduled</td>
        <td>K8sDaemonsetSample</td>
        <td>Gauge</td>
        <td>Updated number of scheduled DaemonSet instances.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_created</td>
        <td>createdAt</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_metadata_generation</td>
        <td>metadataGeneration</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Generation number of the Deployment metadata.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_spec_replicas</td>
        <td>podsDesired</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of desired replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
            <td>kube_deployment_spec_strategy_rollingupdate_max_surge</td>
        <td>rollingUpdateMaxPodsSurge</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Maximum surge allowed during rolling update.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_condition</td>
        <td>conditionAvailable, conditionProgressing</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Deployment status conditions.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_observed_generation</td>
        <td>observedGeneration</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>The most recent generation observed for this Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_replicas</td>
        <td>podsTotal</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_replicas_available</td>
        <td>podsAvailable</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of available replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_replicas_ready</td>
        <td>podsReady</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of ready replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_replicas_unavailable</td>
        <td>podsUnavailable</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of unavailable replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_deployment_status_replicas_updated</td>
        <td>podsUpdated</td>
        <td>K8sDeploymentSample</td>
        <td>Gauge</td>
        <td>Number of updated replicas for the Deployment.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_horizontalpodautoscaler_spec_min_replicas</td>
        <td>minReplicas</td>
        <td>K8sHpaSample</td>
        <td>Gauge</td>
        <td>Minimum number of replicas for the HorizontalPodAutoscaler.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_horizontalpodautoscaler_status_condition</td>
        <td>isActive</td>
        <td>K8sHpaSample</td>
        <td>Gauge</td>
        <td>Status conditions of the HorizontalPodAutoscaler.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_horizontalpodautoscaler_status_current_replicas</td>
        <td>currentReplicas</td>
        <td>K8sHpaSample</td>
        <td>Gauge</td>
        <td>Current number of replicas for the HorizontalPodAutoscaler.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_horizontalpodautoscaler_status_desired_replicas</td>
        <td>desiredReplicas</td>
        <td>K8sHpaSample</td>
        <td>Gauge</td>
        <td>Desired number of replicas for the HorizontalPodAutoscaler.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_complete</td>
        <td>isComplete</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Whether the Job is complete (1) or not (0).</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_created</td>
        <td>createdAt</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_failed</td>
        <td>failed</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Whether the Job has failed (1) or not (0).</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_spec_active_deadline_seconds</td>
        <td>specActiveDeadlineSeconds</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Number of seconds the Job can run before being terminated.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_spec_completions</td>
        <td>specCompletions</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Desired number of successfully finished pods for the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_spec_parallelism</td>
        <td>specParallelism</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Maximum desired number of pods executing in parallel for the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_status_active</td>
        <td>activePods</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Number of active pods for the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_status_completion_time</td>
        <td>completedAt</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Completion time of the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_status_failed</td>
        <td>failedPods</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Number of failed pods for the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_status_start_time</td>
        <td>startedAt</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Start time of the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_job_status_succeeded</td>
        <td>succeededPods</td>
        <td>K8sJobSample</td>
        <td>Gauge</td>
        <td>Number of succeeded pods for the Job.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_node_status_allocatable</td>
            <td>memoryWorkingSetUtilization</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Allocatable resources of the Node.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_node_status_condition</td>
        <td>condition.CONDITION_NAME=CONDITION_VALUE</td>
        <td>K8sNodeSample</td>
        <td>Gauge</td>
        <td>Condition of the Node's status.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolume_capacity_bytes</td>
        <td>capacityBytes</td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Capacity of the PersistentVolume in bytes.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolume_created</td>
        <td>createdAt</td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the PersistentVolume.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolume_info</td>
        <td></td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Information about the PersistentVolume.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolume_status_phase</td>
        <td>statusPhase</td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Phase of the PersistentVolume.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolumeclaim_created</td>
        <td>createdAt</td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the PersistentVolumeClaim.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolumeclaim_info</td>
        <td>All attributes describing the volume</td>
        <td>K8sPersistentVolumeSample</td>
        <td>Gauge</td>
        <td>Information about the PersistentVolumeClaim.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolumeclaim_resource_requests_storage_bytes</td>
        <td>requestedStorageBytes</td>
        <td>K8sPersistentVolumeClaimSample</td>
        <td>Gauge</td>
        <td>Storage resource requests of the PersistentVolumeClaim in bytes.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_persistentvolumeclaim_status_phase</td>
        <td>statusPhase</td>
        <td>K8sPersistentVolumeClaimSample</td>
        <td>Gauge</td>
        <td>Phase of the PersistentVolumeClaim.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_resource_limits</td>
        <td>cpuLimitCores, memoryLimitBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Resource limits of the Pod container.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_resource_requests</td>
        <td>cpuRequestedCores, memoryRequestedBytes</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Resource requests of the Pod container.</td>
        </tr>
        <tr>
            <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_status_phase</td>
        <td>status</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Current phase of the Pod container.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_status_ready</td>
        <td>isReady</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Whether the Pod container is ready (1) or not (0).</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_status_restarts_total</td>
        <td>restartCount</td>
        <td>K8sContainerSample</td>
        <td>Counter</td>
        <td>Total number of restarts for the Pod container.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_container_status_waiting_reason</td>
        <td>reason</td>
        <td>K8sContainerSample</td>
        <td>Gauge</td>
        <td>Reason for the container waiting state.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_created</td>
        <td>createdAt</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the Pod.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_info</td>
        <td>All attributes describing the POD</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Information about the Pod.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_status_phase</td>
        <td>status</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Current phase of the Pod status.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_status_ready</td>
        <td>isReady</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Whether the Pod is ready (1) or not (0).</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_status_ready_time</td>
        <td>startTime</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Time when the Pod status became ready.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_status_scheduled</td>
        <td>isScheduled</td>
        <td>K8sPodSample</td>
        <td>Gauge</td>
        <td>Whether the Pod is scheduled (1) or not (0).</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_pod_status_scheduled_time</td>
        <td></td>
        <td></td>
        <td>Gauge</td>
        <td>Time when the Pod became scheduled.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_annotations</td>
        <td>selector.ANNOTATIONS</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Annotations applied to the Service.</td>
            </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_created</td>
        <td>createdAt</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the Service.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_info</td>
        <td>All attributes describing the Service</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Information about the Service.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_labels</td>
        <td>label.LABEL_NAME</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Labels applied to the Service.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_spec_type</td>
        <td>specType</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Type of the Service specification.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_service_status_load_balancer_ingress</td>
        <td>filter with WHERE specType = 'LoadBalancer'</td>
        <td>K8sServiceSample</td>
        <td>Gauge</td>
        <td>Status of the load balancer ingress for the Service.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_created</td>
        <td>createdAt</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Creation timestamp of the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_persistentvolumeclaim_retention_policy</td>
        <td>filter with WHERE persistent = 'true'</td>
        <td>K8sVolumeSample</td>
        <td>Gauge</td>
        <td>Retention policy of PersistentVolumeClaims for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_replicas</td>
        <td>podsDesired</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Desired number of replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_current_revision</td>
        <td>currentRevision</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Current revision of the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_replicas</td>
        <td>podsTotal</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Number of replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_replicas_available</td>
        <td>podsTotal - podsCurrent</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Number of available replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_replicas_current</td>
            <td>podsCurrent</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Number of current replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_replicas_ready</td>
        <td>podsReady</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Number of ready replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>KubeStateMetrics</td>
        <td>Prometheus Receiver</td>
        <td>kube_statefulset_status_replicas_updated</td>
        <td>podsUpdated</td>
        <td>K8sStatefulsetSample</td>
        <td>Gauge</td>
        <td>Number of updated replicas for the StatefulSet.</td>
        </tr>
        <tr>
        <td>Node</td>
        <td>HostMetric Receiver</td>
        <td>process.cpu.utilization</td>
        <td>cpuPercent</td>
        <td>ProcessSample</td>
        <td>Gauge</td>
        <td>CPU utilization of the process as a percentage.</td>
        </tr>
        <tr>
        <td>Node</td>
        <td>HostMetric Receiver</td>
        <td>process.disk.io</td>
        <td>ioTotalReadCount+ioTotalWriteCount</td>
        <td>ProcessSample</td>
        <td>Counter</td>
        <td>Number of disk I/O operations performed by the process.</td>
        </tr>
        <tr>
        <td>Node</td>
        <td>HostMetric Receiver</td>
        <td>process.memory.usage</td>
        <td>memoryResidentSizeBytes</td>
        <td>ProcessSample</td>
        <td>Gauge</td>
        <td>Memory usage of the process in bytes.</td>
        </tr>
        <tr>
        <td>Node</td>
        <td>HostMetric Receiver</td>
        <td>process.memory.virtual</td>
        <td>memoryVirtualSizeBytes</td>
        <td>ProcessSample</td>
        <td>Gauge</td>
        <td>Virtual memory usage of the process in bytes.</td>
        </tr>
        <tr>
        <td>Node</td>
        <td>HostMetric Receiver</td>
        <td>system.cpu.load_average.15m</td>
        <td>loadAverageFifteenMinute</td>
        <td>SystemSample</td>
        <td>Gauge</td>
        <td>System load average over the last 15 minutes.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.cpu.load_average.1m</td>
            <td>loadAverageOneMinute</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>System load average over the last 1 minute.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.cpu.load_average.5m</td>
            <td>loadAverageFiveMinute</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>System load average over the last 5 minutes.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.cpu.utilization</td>
            <td>cpuPercent</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>Total CPU utilization percentage.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.disk.io</td>
            <td>readBytesPerSecond+writeBytesPerSecond</td>
            <td>StorageSample</td>
            <td>Counter</td>
            <td>Number of disk I/O operations performed.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.disk.io_time</td>
            <td>diskReadsPerSecond+diskWritesPerSecond</td>
            <td>SystemSample</td>
            <td>Counter</td>
            <td>Time spent in disk I/O operations in seconds.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.disk.operation_time</td>
            <td>diskWriteUtilizationPercent</td>
            <td>SystemSample</td>
            <td>Counter</td>
            <td>Total time spent in disk operations in seconds.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.disk.operations</td>
            <td>readIoPerSecond</td>
            <td>StorageSample</td>
            <td>Counter</td>
            <td>Number of disk operations performed.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.filesystem.usage</td>
            <td>diskUsedBytes</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>Usage of filesystem space in bytes.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.filesystem.utilization</td>
            <td>diskUsedPercent</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>Utilization of the filesystem as a percentage.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.memory.usage</td>
            <td>memoryUsedBytes</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>Total memory usage in bytes.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.memory.utilization</td>
            <td>memoryUsedPercent</td>
            <td>SystemSample</td>
            <td>Gauge</td>
            <td>Memory utilization as a percentage.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.network.errors</td>
            <td>transmitErrorsPerSecond</td>
            <td>NetworkSample</td>
            <td>Counter</td>
            <td>Number of network errors.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.network.io</td>
            <td>receiveBytesPerSecond, transmitBytesPerSecond</td>
            <td>NetworkSample</td>
            <td>Counter</td>
            <td>Number of network I/O operations.</td>
        </tr>
        <tr>
            <td>Node</td>
            <td>HostMetric Receiver</td>
            <td>system.network.packets</td>
            <td>transmitPacketsPerSecond+receivePacketsPerSecond</td>
            <td>NetworkSample</td>
            <td>Counter</td>
            <td>Number of network packets transmitted and received.</td>
        </tr>
        <tr>
            <td>Scheduler</td>
            <td>Prometheus Receiver</td>
            <td>go_goroutines</td>
            <td>goGoroutines</td>
            <td>K8sApiServerSample, K8sControllerManagerSample, K8sEtcdSample, K8sSchedulerSample</td>
            <td>Gauge</td>
            <td>Number of goroutines that currently exist.</td>
        </tr>
        <tr>
            <td>Scheduler</td>
            <td>Prometheus Receiver</td>
            <td>process_resident_memory_bytes</td>
            <td>processResidentMemoryBytes</td>
            <td>K8sSchedulerSample</td>
            <td>Gauge</td>
            <td>Resident memory size in bytes.</td>
        </tr>
    </tbody>
</table>


    </Collapser>

</CollapserGroup>

## Troubleshooting [#troubleshooting]

Check out the logs of the Collector pod that's experiencing issues. Run this command:

```shell
    kubectl logs <otel-pod-name> -n newrelic
```

You can also set the `verboseLog` parameter to `true` in the [`nr-k8s-otel-collector`](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#values) Helm chart.

## Common errors [#common-erros]

Check out the [Common errors section](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#common-errors) in our GitHub repository.

## Support [#support]

If you have issues with the OpenTelemetry observability for Kubernetes:

* Have a look at the [issues section on GitHub](https://github.com/newrelic/helm-charts/issues) for any similar problems or consider opening a new issue.
