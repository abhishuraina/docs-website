---
title: New Relic integration for Lambda response streaming 
metaDescription: "Learn how to monitor AWS Lambda functions that utilize response streaming in the New Relic."
freshnessValidatedDate: never
tags:
    - aws
    - lambda
    - response stream monitoring
    - ai monitoring
---


Integrate your AWS [Lambda response streaming](https://aws.amazon.com/blogs/compute/introducing-aws-lambda-response-streaming/) in the New Relic platform to offer advanced monitoring capabilities for Node.js applications, particularly those involving AI workloads. This integration allows you to gain real-time insights into the performance and behavior of your serverless applications that has AI workloads.

This document helps you to:

* Set up Lambda response streaming monitoring.
* Understand the metrics and data available for monitoring Lambda response streaming.
* Learn how to use the New Relic UI to monitor and observe the performance of your Lambda response streaming.

New image needed!

<img
    title="New Relic AI Responses page"
    alt="Lambda response monitoring in the New Relic platform"
    src="/images/ss-ai-response-page.gif"
/>

## Integrate the Lambda response streaming

### Prerequisites [#prerequisites]

* A New Relic account with either an [admin role](/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-managing-users/) or have the Infrastructure manager [add-on role](/docs/accounts/accounts-billing/new-relic-one-user-management/introduction-managing-users/).
* Check that your Lambda function meets our [compatibility and requirements](/docs/serverless-function-monitoring/aws-lambda-monitoring/instrument-lambda-function/compatibility-requirement-lambda-monitoring).
* Install and configure [Lambda monitoring on New Relic](/docs/serverless-function-monitoring/aws-lambda-monitoring/instrument-lambda-function/compatibility-requirement-lambda-monitoring).


### Configure the Lambda response streaming [#configure-response-streaming]

To enable response streaming monitoring for your Node.js Lambda functions:

1. Add the following [environment variable](/docs/serverless-function-monitoring/aws-lambda-monitoring/instrument-lambda-function/env-variables-lambda) to the required Lambda function for New Relic Lambda response streaming monitoring:

    ```bash
    NEW_RELIC_MACHINE_LEARNING_ENABLED=true
    NEW_RELIC_ML_INSIGHTS_EVENTS_ENABLED=true
    NEW_RELIC_AI_MONITORING_ENABLED=true
    ```
2. Save the changes and deploy the function.

    After deployment, you can view the Lambda response streaming data in the New Relic platform. For more information, See (View the Lambda response streaming data)[#view-response-streaming-data].


## Access the Lambda response streaming data [#access-ui]

To view the Lambda response streaming data in the New Relic platform:

1. Log in to your New Relic account.
2. Go to the **left navigation pane > All Capabilities > Serverless Functions**.
3. Select the required Lambda function that utilizes response streaming.
4. Click **AI Responses** in the **More views** section.
    
    <img
        title="New Relic AI Responses page"
        alt="Lambda response monitoring in the New Relic platform"
        src="/images/ss-ai-response-page.gif"
    />

## Key metrics on the AI Responses page [#key-metrics]

On the **AI Responses** page, monitor the following metrics related to AI responses:

<table>
    <thead>
        <tr>
            <th>Metric</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Total response</td>
            <td>Displays the total number of responses generated by the Lambda function.</td>
        </tr>
        <tr>
            <td>Response time</td>
            <td>Displays the time taken for the Lambda function to generate and stream the response.</td>
        </tr>
        <tr>
            <td>Token usage per response</td>
            <td>Displays the number of tokens processed per response.</td>
        </tr>
        <tr>
            <td>Errors</td>
            <td>Lists any errors encountered during the response streaming process.</td>
        </tr>
        <tr>
            <td>Number of calls to LLMs</td>
            <td>Tracks how many times the Lambda function interacts with LLMs to offer insight into usage patterns.</td>
        </tr>
        <tr>
            <td>Average tokens per response</td>
            <td>Provides the average number of tokens processed in each response to understand data volume.</td>
        </tr>
        <tr>
            <td>Positive and negative feedback</td>
            <td>Displays the user feedback sentiment to assess AI response quality.</td>
        </tr>
        <tr>
            <td>Responses with feedback</td>
            <td>Counts responses that have received user feedback for qualitative analysis.</td>
        </tr>
        <tr>
            <td>Average token rate in seconds</td>
            <td>Displays the rate at which tokens are processed to offer insight into processing speed.</td>
        </tr>
    </tbody>
</table>
    
For more about our UI, see [Intro to the New Relic platform](/docs/new-relic-solutions/new-relic-one/introduction-new-relic-platform).

