---
title: Load balancer for Gateway cluster
metaDescription: 'Learn how to set up a load balancer for your Gateway cluster to manage the flow of data from your monitored entities to New Relic.'
tags:
    - New Relic One
    - Pipeline control
---

Implementing a load balancer is crucial for managing scalability and efficiency in data processing through the Pipeline Control Gateway, especially when the Gateway is deployed as a Kubernetes cluster. The following general instructions provide a framework applicable to various environments and load balancer technologies.

1. Assess Load Requirements:

    * Determine expected data throughput and identify potential bottlenecks.
    * Evaluate the number of APM agents and peak load times.

2. Select Load Balancer Type:

    * Choose a software load balancer that integrates well with Kubernetes. Options include cloud-based solutions like AWS Elastic Load Balancer, Google Cloud Load Balancer, or Azure Load Balancer, as well as open-source solutions like NGINX or Traefik.

3. Configure Load Balancer:

    * Set up the load balancer to distribute traffic evenly across multiple Gateway instances within the Kubernetes cluster.
    * Implement health checks to ensure only healthy instances receive traffic.

4. Implement Auto-Scaling:

    * Configure auto-scaling policies to add or remove instances based on predefined thresholds, such as CPU usage or network traffic.
    * Monitor performance metrics to adjust scaling policies as needed.

5. Test and Optimize:

    * Conduct load testing to ensure effective traffic distribution and identify any bottlenecks.
    * Optimize configurations to minimize latency and maximize throughput.

Next, we will explore how to implement a load balancer specifically using AWS services, providing detailed instructions for setting up and configuring an AWS Elastic Load Balancer within a Kubernetes environment.
