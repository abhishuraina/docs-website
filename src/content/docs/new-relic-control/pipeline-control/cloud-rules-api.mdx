---
title: Drop data using Pipeline Cloud Rules
metaDescription: 'Learn how to use the Cloud Rule API to manage data filtering and processing in New Relic Control.'
tags:
    - New Relic One
    - Pipeline control
    - Cloud rules
freshnessValidatedDate: never
---

## Overview [#overview]
To create Pipeline Cloud Rules, you must be on `New Relic Compute` usage-based pricing.

One way to [manage your data ingestion](/docs/data-apis/manage-data/manage-data-coming-new-relic) is by using Pipeline Cloud Rules. Pipeline Cloud Rules offer a powerful method to manage your data ingestion, they enable you to:
* Specify which types of data you do not want to save to your New Relic organization
* Completely drop or filter potentially sensitive data
* Completely drop or filter unimportant data

There are two categories of rules you can create:
* **Drop Data Rule**
  * Drop entire data types or a data subset _(with optional filter)_ using the `Drop data` **action**, with NRQL in the form of:
    ```sql
    DELETE FROM DATA_TYPE_1, DATA_TYPE_2 (WHERE OPTIONAL_FILTER)
    ```

* **Drop Attribute Rule**
  * Drop attributes from data types _(with optional filter)_ using the `Drop attributes` **action**, with NRQL in the form of:
    ```sql
    DELETE dropAttr1, dropAttr2 FROM DATA_TYPE (WHERE OPTIONAL_FILTER)
    ```
  * For this type of rule, you must pass in a non-empty list of **raw** attributes names in the `SELECT` clause.

Pipeline Cloud Rules only apply to data that arrives from the moment you create the rule, they don't delete data that's [already been ingested](/docs/telemetry-data-platform/ingest-manage-data/manage-data/manage-data-retention#data-deletion).

To learn more about what data counts as billable or not, see [Data ingest](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/data-ingest-billing/#usage-calculation).

## Requirements [#requirements]

The following data types can be targeted by Pipeline Cloud Rules:

* APM-reported events
* Browser-reported events
* Mobile-reported events
* Synthetics-reported events
* Custom events _(like those generated by the [APM agent APIs](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents) or the [Event API](/docs/insights/insights-data-sources/custom-data/introduction-event-api))_
* Log data _(you can also [use the UI to drop data](/docs/logs/ui-data/drop-data-drop-filter-rules))_
* Distributed tracing spans
* [Default infrastructure monitoring events](/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data) and [infrastructure integrations](/docs/integrations/infrastructure-integrations/get-started/introduction-infrastructure-integrations) events. Some caveats:
    * When you drop this data, the raw data is deleted, but the aggregated `SystemSample`, `ProcessSample`, `NetworkSample` and `StorageSample` events are still available _(for more on this, see [Data retention](/docs/data-apis/manage-data/manage-data-retention/#infrastructure-data))_. Though still available, this data doesn't count towards ingest and is not billable.
      * Raw infrastructure data is used for alerting, so if you drop that data, you can't alert on it. Because the aggregated data is still available, you may still see that data in charts with time ranges above 59 minutes.
* [Dimensional metrics](/docs/telemetry-data-platform/ingest-manage-data/understand-data/new-relic-data-types#dimensional-metrics). Some caveats:
    * For metrics generated by the [events-to-metrics service](/docs/data-ingest-apis/get-data-new-relic/metric-api/events-metrics-service-create-metrics): Pipeline Cloud Rules won't work but these metrics can be stopped or attributes pruned by disabling or re-configuring the events-to-metric rule.
      * Metric timeslice data can't be dropped with Pipeline Cloud Rules. For more information about APM metric timeslice data see [this doc](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data).

## NRQL restrictions [#restrictions]

* The limit on NRQL query length is 4096 characters. If it exceeds the length the nerdGraph will throw an error `INVALID_NRQL_TOO_LONG`. If you need to drop data based on a longer query that cannot be split, please contact your New Relic representative.
* `JOIN` and [subqueries](/docs/query-your-data/nrql-new-relic-query-language/get-started/subqueries-in-nrql) are not supported.
* You can provide a [`WHERE`](/docs/query-data/nrql-new-relic-query-language/getting-started/nrql-syntax-clauses-functions#sel-where) clause to select data with specific attributes. 
* Features such as `LIMIT`, `TIMESERIES`, `COMPARE WITH`, `FACET`, and other clauses cannot be used.
* `SINCE` and `UNTIL` are not supported. If you have time-specific rules _(say, drop everything until a time in the future)_, use `WHERE timestamp < (epoch milliseconds in the future)`.
* You can't use `SINCE` to drop historical data. Pipeline Cloud Rules only apply to data reported after the rule was created. If you need to delete data that has already been reported, contact your New Relic representative.

## Audit rule history [#history]

To see who created and deleted Pipeline Cloud Rules, query your [account audit logs](/docs/insights/use-insights-ui/manage-account-data/query-account-audit-logs-nrauditevent). The [list endpoint](#view-rules) also includes the user ID of the person who created the rule.

## Cautions when dropping data [#caution]

Pipeline Cloud Rules apply to each data point independently. For example, let's look at the following three `Data drop` rules:
```sql 
1. DELETE FROM MyEvent WHERE myAttr not in ('staging')
2. DELETE FROM MyEvent WHERE myAttr not in ('production')
3. DELETE FROM MyEvent WHERE myAttr in ('development')
```
These three rules are applied independently to each data point; in summary, all `MyEvent` events containing `myAttr` with any value will be dropped:
* `myAttr: 'staging'` -> matches rule 2
* `myAttr: 'production'` -> matches rule 1
* `myAttr: 'development'` -> matches rules 1, 2, and 3
* `myAttr: 'uuid-random-string'` -> matches rules 1 and 2

When creating rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic.

New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic does not review or monitor how effective the rules you develop are.

Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Rules you create, including all information in those rules, can be viewed and edited by any user with the relevant role-based access control permissions.

Only new data will be dropped. Existing data [cannot be edited or deleted](/docs/telemetry-data-platform/ingest-manage-data/manage-data/manage-data-retention#data-deletion).

# Managing Pipeline Cloud Rules [#how-to]
To create and edit rules, you can either use the [Pipeline Control UI](/docs/todo/replace/with/pipeline/control/ui/usage/doc) or the [NerdGraph](/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph) API explorer _(**[one.newrelic.com](https://one.newrelic.com) > Apps > NerdGraph API explorer**)_.

<Callout variant="caution">
  Use caution when deciding to drop data. The data you drop can't be recovered. For more details on potential issues, see [Caution notes](#caution).
</Callout>

## Use Case Examples [#example-mutations]

<CollapserGroup>
  <Collapser
    id="drop-events"
    title="Drop two event types"
  >
    Let's say you notice you have some event types being sent to New Relic that are not important to you. Also, stopping the source from sending those event types quickly is unrealistic, requiring changes to agents and/or API instrumentation. Using a Pipeline Cloud Rule is an easier way to accomplish the same goal.

    Here is an example NerdGraph call that drops two event types: `Event1` and `Event2`.

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Event1 and Event2 are unimportant, see ticket DM-1234", 
          name: "Drop all data for Event1 and Event2",
          nrql: "DELETE FROM Event1, Event2",
          scope: {
            id: "your_nr_account_id", 
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-specific-events"
    title="Drop events meeting certain criteria"
  >
    Let’s say you have a high volume custom event type that arrives from multiple sources. If you don't find all of that data important, you can use a Pipeline Cloud Rule. Here is an example of a Pipeline Cloud Rule that filters out events based on specific criteria.

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Drops all data for MyCustomEvent that comes from the LoadGeneratingApp in the dev environment, because there is too much and we don’t look at it", 
          name: "Drop MyCustomEvent from LoadGeneratingApp in dev",
          nrql: "DELETE FROM MyCustomEvent WHERE appName='LoadGeneratingApp' AND environment='development'",
          scope: {
            id: "your_nr_account_id", 
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-sensitive-data"
    title="Drop sensitive attributes while maintaining the rest of the data"
  >
    Let's say you noticed an event has attributes that contain Personally Identifiable Information (PII). You are working to update your services to stop sending the data, but until then, you need to cease storing further PII in New Relic. Although you could drop all of the data as it comes in the door with `Drop data`, the rest of the data still provides value. Therefore, you can register a Pipeline Cloud Rule to remove only the offending PII from your data:

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Removes the user name and email fields from MyCustomEvent", 
          name: "Drop username and email from MyCustomEvent",
          nrql: "DELETE userName, userEmail FROM MyCustomEvent",
          scope: {
            id: "your_nr_account_id", 
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>
</CollapserGroup>

## Verify your rule works [#verify]

After you create a Pipeline Cloud Rule, you might wish to verify that it is working as expected. The rule should take effect quickly after a successful registration, so try running a `TIMESERIES` version of the query you registered to see that the data drops off.

_Note: Timeseries data is rendered with event time (not processing time) as the x-axis. Since New Relic accepts data with a timestamp up to twenty-four hours in the future, you might see some data that was sent to New Relic before the rule was created but with an event timestamp past rule creation._



<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Pipline Cloud Rule Type
      </th>

      <th>
        NRQL
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `Drop data`
      </td>

      <td>
        <DNT>
          **Pipeline Cloud Rule NRQL:**
        </DNT>

        ```sql
        DELETE FROM MyEvent WHERE foo = bar
        ```

        <DNT>
          **Validation NRQL:**
        </DNT>

        ```sql
        SELECT count(*) FROM MyEvent WHERE foo = bar TIMESERIES
        ```

        This should drop to 0. To verify that it did not affect any thing else, invert the `WHERE` clause.
      </td>
    </tr>

    <tr>
      <td>
        `Drop attributes`
      </td>

      <td>
        <DNT>
          **Pipeline Cloud Rule NRQL:**
        </DNT>

        ```sql
        DELETE dropAttr1, dropAttr2 FROM MyEvent WHERE foo = bar
        ```

        <DNT>
          **Validation NRQL:**
        </DNT>

        ```sql
        SELECT count(dropAttr1), count(dropAttr2) FROM MyEvent WHERE foo = bar TIMESERIES
        ```

        Both lines should drop to 0. To verify that it did not affect events that contained these attributes and still should, invert the `WHERE` clause.
      </td>
    </tr>
  </tbody>
</table>

# NerdGraph Examples [#examples]

## Create Pipeline Cloud Rules [#create-rules]

Drop data:
```graphql
mutation {
  entityManagementCreatePipelineCloudRule(
    pipelineCloudRuleEntity: {
      description: "Since we only care about MyEvent in staging and production, let's drop all MyEvent data in the test environment", 
      name: "Drop MyEvent in test environment",
      nrql: "DELETE FROM MyEvent where environment = 'test'",
      scope: {
        id: "your_nr_account_id", 
        type: ACCOUNT
      }
    }
  ) {
    entity {
      id
      name
      nrql
    }
  }
}
```

Drop attributes:
```graphql
mutation {
  entityManagementCreatePipelineCloudRule(
    pipelineCloudRuleEntity: {
      description: "Since we only care about MyEvent in staging and production, let's drop all MyEvent data in the test environment", 
      name: "Drop MyEvent in test environment",
      nrql: "DELETE jvmId, targetAttr FROM MyEvent where environment = 'test'",
      scope: {
        id: "your_nr_account_id", 
        type: ACCOUNT
      }
    }
  ) {
    entity {
      id
      name
      nrql
    }
  }
}
```
## Delete a Pipeline Cloud Rule [#delete-rule]

```graphql
mutation {
  entityManagementDelete(id: "MTAyNTY1MHxOR0VQfFBJUEVMSU5FX0NMT1VEX1JVTEV8MDE5NWI0NDYtNjk5My03NGE5LWEyYjktMzBjMzQ1ODM0NTUz") {
    id
  }
}

```

## View Pipeline Cloud Rules [#view-rules]

Get a single Pipeline Cloud Rule:

```graphql
{
  actor {
    entityManagement {
      entity(id: "MTAyNTY1MHxOR0VQfFBJUEVMSU5FX0NMT1VEX1JVTEV8MDE5NWI0M2UtYmFhNy03NDk3LWI0N2ItNjUyMmEzZDFmZTFi") {
        id
        ... on EntityManagementPipelineCloudRuleEntity {
          id
          name
          description
          nrql
          metadata {
            createdBy {
              id
            }
            createdAt
          }
        }
      }
    }
  }
}
```

List all Pipeline Cloud Rules:

```graphql
{
  actor {
    entityManagement {
      entitySearch(query: "type = 'PIPELINE_CLOUD_RULE'") {
        entities {
          id
          type
          ... on EntityManagementPipelineCloudRuleEntity {
            id
            name
            nrql
          }
          metadata {
            createdBy {
              id
            }
          }
        }
      }
    }
  }
}

```

## Prohibited Events and Attributes [#banned-events-and-attributes]

<CollapserGroup>
  <Collapser
    id="prohibited-events"
    title="Prohibited Events"
  >
    <table>
      <thead>
        <tr>
          <th>Event Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>NrAuditEvent</td>
          <td>Important auditing information about the API usage that can’t be dropped.</td>
        </tr>
        <tr>
          <td>NrIntegrationError</td>
          <td>Important information about issues between you and New Relic.</td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="prohibited-attributes"
    title="Prohibited Attributes"
  >
    <table>
      <thead>
        <tr>
          <th>Attribute</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Any `nr.` prefixed attribute</td>
          <td>Used internally by New Relic</td>
          <td></td>
        </tr>
        <tr>
          <td>`timestamp`</td>
          <td>Integral to all data types</td>
        </tr>
        <tr>
          <td>`appId`</td>
          <td>Integral to all data types</td>
        </tr>
        <tr>
          <td>`metricName`</td>
          <td>Integral to the Metric data type</td>
        </tr>
        <tr>
          <td>`instrumentation.provider`</td>
          <td>Used for billing and usage data</td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Learn more

Recommendations for learning more:

* [NerdGraph basics and terminology](/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph#terminology)
* [NRQL basics](/docs/query-data/nrql-new-relic-query-language/getting-started/introduction-nrql)
* Browse the [Support Forum](https://discuss.newrelic.com/c/telemetry-data-platform/dashboards) for community discussions about Pipeline Cloud Rules.
* For a deep dive into managing data ingest for a complex organization, see [Data ingest governance](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).
