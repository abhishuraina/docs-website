---
title: Understanding Ingest Pipeline Architecture
metaDescription: 'Learn how to understand the architecture of the ingest pipeline in New Relic.'
tags:
    - New Relic One
    - Pipeline control
    - Ingest pipeline
freshnessValidatedDate: never
---

In this section, you'll explore the ingest pipeline architecture, which visually represents how your telemetry data flows through the system. You'll see how using Gateway and Cloud Rules can impact data volume and optimize your data management strategy.

## Components of Your Ingest Pipeline [#components-ingest-pipeline]

1. MELT Sources:
    
    * Metrics, Events, Logs, and Traces (MELT): These are the primary types of observability data you collect from various sources. They form the starting point of your ingest pipeline.

2. Data Flow Lines:

    * Lines emanate from each MELT source, representing the data being sent to the NRDB. Each line is annotated with a data volume, measured in millions (M), indicating the amount of data processed.

3. Gateway:

    * Positioned between MELT sources and Cloud Rules, the Gateway acts as a filter, applying your user-defined rules to drop low-value data before it exits your network. This reduces the data volume sent to the NRDB, optimizing storage and egress costs.

4. Cloud Rules:

    * Cloud Rules are applied within the New Relic Cloud, further filtering data before it reaches the NRDB. The diagram indicates the number of operational Cloud Rules, providing insight into your current data management strategy.

5. NRDB:

    * The New Relic Database (NRDB) is the final destination for processed data. It stores the refined telemetry data, ready for your analysis and visualization.

### Visual Representation [#visual-representation]

* Without Gateway and Cloud Rules:

    * The diagram shows direct lines from MELT sources to NRDB, with higher data volumes due to the absence of filtering.

* With Gateway and Cloud Rules:

    * The diagram illustrates reduced data volumes as lines pass through the Gateway and Cloud Rules, highlighting the efficiency gained through rule-based data dropping.

<callout variant="tip">
    Use the time picker to narrow down or widen the timeframe for the data represented in the ingest pipeline.
</callout>


## DELETE Keyword in NRQL [#delete-keyword]

The **DELETE** keyword in New Relic Query Language (NRQL) is used to remove specific data and attributes within Pipeline Control. This helps manage the data that is ingested into the New Relic Database (NRDB).

### Usage

The **DELETE** keyword is applied in NRQL queries to specify which data or attributes should be removed. Here are some examples:

### Example Rules

1. **Deleting Specific Metrics:**

    ```sql
        DELETE FROM Metric WHERE metricName = 'newrelic.goldenmetrics.infra.kubernetes_pod.podScheduled'
    ```

    * Removes metrics with the specified name.

2. **Deleting Specific Spans:**

    ```sql 
    DELETE FROM Span WHERE appName = 'external-usage-consumer (test-odd-wire)'
    ```

    * Removes spans associated with the specified application.

3. **Deleting Specific Agent Updates:**

    ```sql
    DELETE FROM AgentUpdate WHERE a = 'b'
    ```

    * Removes agent updates where the attribute `a` equals `b`.
